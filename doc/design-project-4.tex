\documentclass[11pt]{article}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{fullpage}

\title{6.035 Project 4 Design Document}
\author{Kyle Miller, Alec Thomson, Patrick Hulin, Steven Valdez}
\begin{document}
\maketitle

\section {Overview} 

For the final optimization project of our compiler, we plan to split
the work into several significant chunks of optimizations to make good
use of the large size of our team. The two major optimizations we plan
to implement include a Register Allocator (Section~\ref{sec:register}) and a Loop
Parallelizer (Section~\ref{sec:parallel}). Smaller optimizations we plan to implement include
Loop-Invariant Code Motion (Section~\ref{sec:codehoist}), Algebraic
Simplification (Section~\ref{sec:algebra}), Tailcall Optimizations
(Section~\ref{sec:tailcall}), an Expression
Unflattener (Section~\ref{sec:unflatten}), and a variety of Peephole
Optimizations (Section~\ref{sec:peephole}). 

Our test plan (Section~\ref{sec:test}) is designed to test for correctness on many levels and
to provide us with useful information about the effectiveness of our
optimizations. Finally, the order in which we perform these
optimizations is discussed in Section~\ref{sec:order}.

\section {Division of Work}

Right now, our plan is to split the optimizations amongst ourselves as
follows: Kyle Miller will design and implement the Register
Allocator, Tailcall Optimizer, and Algebraic Simplifications. Alec Thomson will design and implement the Loop
Parallelizer and the Expression Unflattener. Steven Valdez will design and implement the Peephole
Optimizations. Finally, Patrick Hulin will design and implement
Loop-Invariant Code Motion and be in charge of the test system. 

\section {Register Allocator}
\label{sec:register}

Register allocation is the most important optimization we hope to
implement for our optimized compiler. Fortunately, it is a very
well-defined and well-documented problem, so we plan to make use of
extensive materials while implementing a standard solution. 

The current plan for our register allocator, which operates at nearly
the lowest level of our compiler, is to implement the
algorithm as described by Muchnick in the register allocation
section. The final register allocator will be a combination of
liveness analysis and graph coloring with a set of heuristics to
approximate the optimal solution to the graph coloring problem. 

We expect to see the code generator output 20-25\% fewer instructions
then it currently does, the largest speedup by far. Most instructions
currently are superfluous moves to and from the stack.

\section {Loop Parallelizer}
\label{sec:parallel}

The purpose of the Loop Parallelizer is to make better use of a multicore
system by splitting up independent loops into multiple threads of
execution. The general idea is that if each iteration of a loop does
not depend on any of the other iterations, the order of execution of
the iterations does not matter and each iteration can be run on a
different core of the system. For example, the following loop could be
parallelized 

\begin{verbatim}
for (i = 0 : N) {
  A[i] = i; 
}
\end{verbatim} 

Our loop parallelizer will operate on the mid-ir by first determining
which loops can be parallelized and then annotating appropriate blocks
with instructions to parallelize. The code generator will then
systematically create code to generate extra threads of execution upon encountering
these annotations.

To find the loops in our mid-ir, we can make use of our dataflow
framework from the previous project to do ``Dominator Analysis''. 

Since Loop parallelization can be quite tricky, our initial design
only focuses on a select subset of parallelizable loops. For example,
our initial design only parallelizes
loops whose iterations are \textbf{completely independent} of each
other in terms of data used. Such a design hopes to minimize the
number of locks used and avoid complexity such as message passing in
between dependent iterations.\\

Finally, since the decaf language doesn't allow the arbitrary use of
pointers, variable alias analysis (where variables are analyzed to
determine if they represent the same memory location) will not be
necessary, further simplifying the analysis of loop parallelization. 

In terms of implementation, we plan to make use of the provided C
libraries to perform the actual generation of threads and locking of
shared memory structures.  

\section {Expression Unflattener}
\label{sec:unflatten}

The Expression Unflattener is an optimization that returns the
Control-Flow Graph to ``Tree-form'' after CSE is performed. As
explained in our previous project writeup, the mid-ir is initially constructed
in tree-form (where expressions are not flattened into simple unary
and binary op forms) because the code generator can pattern match over
expression trees to determine the best possible assembly
instruction to use for certain expressions. Tree-form is particularly
useful for memory addressing as the code generator can make use of
complex x86 move instructions when possible.\\

To perform CSE during the last project, the mid-ir had to first be
``Flattened'' so that common subexpressions could be identified. For
example, an expression such as 

\begin{verbatim}
x := i + (j * y)
\end{verbatim} 

\noindent would be flattened to 

\begin{verbatim}
t := j * y 
x := i + t
\end{verbatim}

To make effective use of our code generator and to reap the full
benefits of CSE, this flattened form of the mid-ir should be restored
to tree-form while maintaining all of the benefits achieved by CSE. 

To do so, our design first makes use of the liveness information
provided by dead-code elimination to determine which variables are
live at any given block in the mid-ir control flow graph. Once this
information is obtained, unflattening can be performed at the block
level.\\


\noindent Each block is then re-written according to the following algorithm: 

\begin{verbatim}
UnflattenBlock(block):

1. Determine the number of uses of each variable in this block 
2. Determine the reaching definitions of each variable defined in this
block
3. For each variable of each expression in this block: 
   1. If the variable is not live at any of this blocks successors 
      AND the variable is only used once in this entire block 
      (i.e. this is the only use)
      AND the variable is mapped to a reaching definition from this block 
   4. THEN replace the use of this variable with the expression from
its reaching definition
\end{verbatim}

\noindent The UnflattenBlock function is run on the same block until that block
reaches a fixed point. The general purpose of this algorithm is to
discover variables that are ``temporary'' in a given block and to replace
their uses with the expressions they were assigned to represent during
the flattening phase. Since the algorithm doesn't consider a variable
``temporary'' if it is used more than once (or if it is live in a
successor of this block), the benefits of CSE should be preserved
while the mid-ir is returned to tree-form. 

\section {Tail-Call Recursion}
\label{sec:tailcall}

\section {Algebraic Simplification}
\label{sec:algebra}

Algebraic Simplification is the process of simplifying basic algebraic
identities (such as \begin{verbatim}x := y * 1 \end{verbatim}) to
produce simpler code. 

Our algebraic simplifier is a basic extension of the constant
propagator we produced as part of the previous project. We make use of
Hoopl's graph rewrite functionality to check a given expression
against a series of simplification rules we define in a separate
module. Our rules are defined by a DSL and we require a valid
justification for each rule since some rules can have unintended
consequences (such as attempting to negate the most negative
integer). 

To avoid producing incorrect code as a result of algebraic
simplification, we plan to change the mid-ir so that ``Division
Operations'' (which include both divides and mods) are instructions
separate from ``pure'' expressions. The reason for this is that
division operations are capable of producing side-effects in the form
of divide by zero exceptions, so our algebraic simplifier is safer
when it only operates on ``pure'' expressions. 



\section {Loop Invariant Code Motion}
\label{sec:codehoist}

\section {Peephole Optimizations and other Small Optimizations}
\label{sec:peephole}

\section {Test Plan}
\label{sec:test}

Our test plan consists of several redundant factors to increase the
probability that we catch any errors with our compiler. First, our
test suite includes a set of shell scripts that make use of every test
we've written inside a certain ``testing directory''. We also plan to
implement a ``Decaf to C'' compiler that produces valid C code from a
valid decaf program and uses GCC to produce the expected
output. Finally, to test correctness of our compiler even further, we
also plan to implement a complex and ``Real'' decaf program, which in
our case is a VM for a very simple stack-based programming language. 

\subsection {Testing Scripts}

\subsection {Decaf to C Converter} 

\subsection {Large ``Real'' Decaf Program}


\section {Ordering of Optimizations} 
\label{sec:order}

The order of the optimizations is important for their
effectiveness. The general order of our optimizations, which we derived
in part from Muchnick, is as follows: 

\begin{enumerate}

\item Constant Propagation immediately followed by Algebraic
  Simplification 

\item Initial Tail Call Optimizations 

\item Elimination of superfluous blocks 

\item Global CSE (with flattening of the mid-ir)

\item Global Copy Propagation

\item Dead Code Elimination

\item Unflattening of the mid-ir 

\item Dead Code Elimination again to remove anything missed by the
  unflattener 

\item Loop Invariant Code Motion

\item Another Tail Call pass 

\item Another Dead Code Elimination pass 

\item Another Block elimination pass 

\item Loop Parallelization

\item Initial Peephole Optimizations including peephole instruction selection

\item Register Allocation

\item Peephole Optimizations again including more instruction selection

\end{enumerate}

\noindent It is our goal with this ordering to produce the best possible use of
our individual optimizations. 

\end{document}