\documentclass[11pt]{article}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{fullpage}

\title{6.035 Project 4 Design Document}
\author{Kyle Miller, Alec Thomson, Patrick Hulin, Steven Valdez}
\begin{document}
\maketitle

\section {Overview} 

For the final optimization project of our compiler, we plan to split
the work into several significant chunks of optimizations to make good
use of the large size of our team. The two major optimizations we plan
to implement include a Register Allocator (Section~\ref{sec:register}) and a Loop
Parallelizer (Section~\ref{sec:parallel}). Smaller optimizations we plan to implement include
Loop-Invariant Code Motion (Section~\ref{sec:codehoist}), Algebraic
Simplification (Section~\ref{sec:algebra}), Tailcall Optimizations
(Section~\ref{sec:tailcall}), an Expression
Unflattener (Section~\ref{sec:unflatten}), and a variety of Peephole
Optimizations (Section~\ref{sec:peephole}). 

Our test plan (Section~\ref{sec:test}) is designed to test for correctness on many levels and
to provide us with useful information about the effectiveness of our
optimizations. 

\section {Division of Work}

Right now, our plan is to split the optimizations amongst ourselves as
follows: Kyle Miller will design and implement the Register
Allocator, Tailcall Optimizer, and Algebraic Simplifications. Alec Thomson will design and implement the Loop
Parallelizer and the Expression Unflattener. Steven Valdez will design and implement the Peephole
Optimizations. Finally, Patrick Hulin will design and implement
Loop-Invariant Code Motion and be in charge of the test system. 

\section {Register Allocator}
\label{sec:register}

\section {Loop Parallelizer}
\label{sec:parallel}

The purpose of the Loop Parallelizer is to make better use of a multicore
system by splitting up independent loops into multiple threads of
execution. The general idea is that if each iteration of a loop does
not depend on any of the other iterations, the order of execution of
the iterations does not matter and each iteration can be run on a
different core of the system. For example, the following loop could be
parallelized 

\begin{verbatim}
for (i = 0 : N) {
  A[i] = i; 
}
\end{verbatim} 

Our loop parallelizer will operate on the mid-ir by first determining
which loops can be parallelized and then annotating appropriate blocks
with instructions to parallelize. The code generator will then
systematically create code to generate extra threads of execution upon encountering
these annotations.

Since Loop parallelization can be quite tricky, our initial design
only focuses on a select subset of parallelizable loops. For example,
our initial design only targets for loops and then only parallelizes
loops whose iterations are \textbf{completely independent} of each
other in terms of data used. Such a design hopes to minimize the
number of locks used and avoid complexity such as message passing in
between dependent iterations.\\

Finally, since the decaf language doesn't allow the arbitrary use of
pointers, variable alias analysis (where variables are analyzed to
determine if they represent the same memory location) will not be
necessary, further simplifying the analysis of loop parallelization. 

In terms of implementation, we plan to make use of the provided C
libraries to perform the actual generation of threads and locking of
shared memory structures.  

\section {Expression Unflattener}
\label{sec:unflatten}

The Expression Unflattener is an optimization that returns the
Control-Flow Graph to ``Tree-form'' after CSE is performed. As
explained in our previous project writeup, the mid-ir is initially constructed
in tree-form (where expressions are not flattened into simple unary
and binary op forms) because the code generator can pattern match over
expression trees to determine the best possible assembly
instruction to use for certain expressions. Tree-form is particularly
useful for memory addressing as the code generator can make use of
complex x86 move instructions when possible.\\

To perform CSE during the last project, the mid-ir had to first be
``Flattened'' so that common subexpressions could be identified. For
example, an expression such as 

\begin{verbatim}
x := i + (j * y)
\end{verbatim} 

\noindent would be flattened to 

\begin{verbatim}
t := j * y 
x := i + t
\end{verbatim}

To make effective use of our code generator and to reap the full
benefits of CSE, this flattened form of the mid-ir should be restored
to tree-form while maintaining all of the benefits achieved by CSE. 

To do so, our design first makes use of the liveness information
provided by dead-code elimination to determine which variables are
live at any given block in the mid-ir control flow graph. Once this
information is obtained, unflattening can be performed at the block
level.\\


\noindent Each block is then re-written according to the following algorithm: 

\begin{verbatim}
UnflattenBlock(block):

1. Determine the number of uses of each variable in this block 
2. Determine the reaching definitions of each variable defined in this
block
3. For each variable of each expression in this block: 
   1. If the variable is not live at any of this blocks successors 
      AND the variable is only used once in this entire block 
      (i.e. this is the only use)
      AND the variable is mapped to a reaching definition from this block 
   4. THEN replace the use of this variable with the expression from
its reaching definition
\end{verbatim}

\noindent The UnflattenBlock function is run on the same block until that block
reaches a fixed point. The general purpose of this algorithm is to
discover variables that are ``temporary'' in a given block and to replace
their uses with the expressions they were assigned to represent during
the flattening phase. Since the algorithm doesn't consider a variable
``temporary'' if it is used more than once (or if it is live in a
successor of this block), the benefits of CSE should be preserved
while the mid-ir is returned to tree-form. 

\section {Tail-Call Recursion}
\label{sec:tailcall}

The Tail-Call Recursion optimization is an optimization that avoids
allocating a new frame in the stack because the caller will simply
return the value of the call. In the ``tree-form'' of the MidIR, this
optimization would eliminate calls of this form, and instead create an
edge between the caller and inside the callee.\\

Since Tail-Call Recursion can have side effects, and is inherently
difficult to construct a lattice for across multiple methods, our
initial design focuses on only Tail-Call Recursion across calls with
the \textbf{same caller and callee methods}. In future revisions of
this optimization, we hope to increase the optimization across
seperate methods in order to take more advantage of this optimization
in non-self recursive methods.

To perform this optimization, for each method in the program, we keep
track of the returns from each method, and create a Lattice with the
Return type of each method, and then apply the Tail-Call optimization
to calls at the end of methods that match the form where the caller
and callee are both the same method, and the current pass over the
Lattice is focusing on that function. Once we've found a location
where a Tail-Call optimization can be performed, we reconstruct the
midir graph to remove the call from that block, and add an edge
between the node with the caller, and a node with the callee.


\section {Algebraic Simplification}
\label{sec:algebra}

\section {Loop Invariant Code Motion}
\label{sec:codehoist}

\section {Peephole Optimizations and other Small Optimizations}
\label{sec:peephole}
In addition to the above major optimizations, we additionally plan to
implement various Peephole Optimizations and other smaller
optimizations to further improve the performance of the assembled
code.\\

The Peephole optimizations that we intend to perform include Strength
Reduction, Constant Folding, Null Sequence optimizations. Strength
Reduction is the optimization where slower optimizations are replaced
by faster optimizations, such as replacing:\\

\begin{verbatim}
a = b * 4;
t = 0;
for(i=0;10)
  t += i * a;
\end{verbatim}

with:\\

\begin{verbatim}
a = b >> 2;
t = 0;
k = 0;
for(i=0;10)
{
  t += k;
  k += a;
}
\end{verbatim}

Meanwhile, Constant Folding is the optimization where $10*2*30$ is
immediately evaluated as $600$. This would reduce the amount of
arithmetic operations that need to be done at run-time and rather move
as many of them as possible to compile-time.

The Null Sequence optimization, which we already partially do, is an
optimization that would remove any code that has no effect on the
running code, and that has no side-effects throughout the
program. This is a lower level version of Dead Code Elimination, which
we are planning to run at the Assembly level in order to remove any
remaining dead code that is produced from the conversion of the midir
graph to the Assembly Code.

\section {Test Plan}
\label{sec:test}

Our test plan consists of several redundant factors to increase the
probability that we catch any errors with our compiler. First, our
test suite includes a set of shell scripts that make use of every test
we've written inside a certain ``testing directory''. We also plan to
implement a ``Mid-IR to C'' compiler that produces valid C code from a
valid decaf program's middle IR and uses GCC to produce the expected
output. Finally, to test correctness of our compiler even further, we
also plan to implement a complex and ``Real'' decaf program, which in
our case is a VM for a very simple stack-based programming language.

\subsection {Testing Scripts}

All the tests from each stage have been compiled into a single
directory with a single testing script. This script will run the test,
and if that test fails, it will run the Mid-IR to C converter with no
optimizations to determine whether the problem is a result of
optimizations or a result of code generation. 

\subsection {Mid-IR to C Converter} 

The Mid-IR to C converter converts from our middle IR to C. The Mid-IR
preserves the function call abstraction, but not internal control
flow. The C code is human readable, and enables us to see the results
of programs before we do register allocation and code generation.

\subsection {Large ``Real'' Decaf Program}


\end{document}
