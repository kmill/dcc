\documentclass[11pt]{article}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{fullpage}

\title{6.035 Project 1}
\author{Kyle Miller, Patrick Hulin, Alec Thomson, Steven Valdez}
\begin{document}
\maketitle

\section{Overview} 

For this project, we extended the decaf scanner/parser created in project 0 to 
check for semantic errors and to build a useful intermediate representation for 
code generation. The project is split up into two distinct phases that can 
occur in parallel: semantic checking and IR generation. 

When \texttt{--target inter} is specified on the command line, the compiler 
will perform all semantic checks on the input program. If there are no semantic 
errors and \texttt{--debug} is specified, the compiler will then generate a 
``Hybrid AST'' (outlined in Section~\ref{sec:ir}) and print this IR to the 
terminal. The return values of the program specify whether or not the semantic 
checker passed or failed. Currently, the only error code is 1, though this may 
possibly be changed in future versions.

\section{Division of Work} 

For this project, Kyle wrote all of the code corresponding to the
actual semantic checker (Section~\ref{sec:checker}), available in
SemanticCheck.hs, and Unify.hs. Alec wrote the code corresponding to
the IR for Code Generation (Section~\ref{sec:ir}) available in
SymbolTable.hs. Patrick created a large suite of test-cases
(Section~\ref{sec:test}) that went beyond the cases provided in the
skeleton. Steven identified errors and proposed solutions. 

\section{Semantic Checker}
\label{sec:checker}

The semantic checker takes the AST generated by the parser and
determines whether the AST is semantically valid by evaluating the
tree in a context which keeps track of the types of all of the
variables defined in the current lexical scope, whether the current
scope is inside a looping construct, the current unification data, and
a list of all of the discovered semantic errors.

For semi-intelligent error messages, we decided to use the unification
algorithm to drive the type-checking required by the semantics for
Decaf.  This gives the semantic checker the ability to infer the types
of undefined variables to provide the user with helpful error message
as well as to be able to simplify the problem of over-reporting an
error (for instance, if \texttt{x} is an undefined variable, then the
expression \texttt{x + x} will only report one error, that \texttt{x}
is undefined, since unification will infer that \texttt{x} must be an
integer for addition to make sense).

The unification algorithm take two structures, which in our case are
trees representing types, where free variables (called ``unification
variables'') can be used in place of substructures, and finds minimal
assignments to the variables which makes the two structures equal.
For instance, unifying \texttt{Array($x$)} with \texttt{Array(Int)}
gives the binding $x=\mathtt{Int}$.  A unification error occurs when
two structures are unable to be unified, such as \texttt{Int} with
\texttt{Bool} or \texttt{Array(Int)} with \texttt{Func($x$, [Int,
  Boolean])}.

The unification algorithm occurs in a unification monad of the
typeclass \texttt{BindingMonad} (defined in \texttt{Unify.hs}) which
keeps track of the bindings for unification variables and generates
new unification variables as needed.  When a \texttt{BindingMonad}
reaches a unification error, the entire computation short circuits
with an exception.

The semantic checker monad defined in \texttt{SemanticCheck.hs} holds
a copy of the \texttt{BindingMonad} state so that unification
variables can be remembered through the entire semantic check.  This
prevents the code \texttt{x = 1; x += 2;} when \texttt{x} is not
defined from issuing more errors than the error of \texttt{x} not
being defined.  The actual mechanism by which this is accomplished is
that, when checking \texttt{x = 1;}, the semantic checker evaluates
the types for \texttt{x} and \texttt{1}.  The integer literal
\texttt{1} is of type \texttt{Int}, and, since the location \texttt{x}
is not defined, the semantic checker adds it to the current lexical
scope with a new unification variable $x$ as its type.  Since
assignment requires that both sides be of the same type, we unify $x$
with \texttt{Int}, giving $x=\mathtt{Int}$.  Hence, when checking
\texttt{x += 2;}, we know that the location \texttt{x} in the
expression has \texttt{Int} as its type.

In particular, the unification lets us write code like the following,
which is almost what is found in \texttt{SemanticCheck.hs} except that
source position handling has been removed.  The operator \texttt{<==>}
is the unification operator, representing equality with the action of
inserting bindings from one structure into the other and vice versa.

\begin{verbatim}
checkStatement (AssignSt loc assop expr)
    = do dtype <- checkLocation loc
         etype <- checkExpr expr
         case assop of
           Assign -> do checkIsScalar etype
                        dtype <==> etype
           -- Otherwise, assop is IncAssign or DecAssign
           _ -> do etype <==> tInt
                   dtype <==> tInt
\end{verbatim}

With the input having the \texttt{x = 1; x += 2;} example, the above
code issues only the following error.
\begin{verbatim}
"<stdin>" (line 3, column 5)
    x = 1;
    ^
Unbound identifier "x".  Inferred type is "int".
\end{verbatim}

The unification operator, on a unification error, appends the error to
the list of discovered semantic errors inside the semantic check
monad.  Other semantic checks are handled in ways analogous to the way
\texttt{break} statements are handled:
\begin{verbatim}
checkStatement (BreakSt pos)
    = do env <- ask
         case isInsideLoop env of
           True -> return ()
           False -> addError $ SemBreakOutsideLoop pos
\end{verbatim}%$
Loops (such as the \texttt{for} statement included below) set whether
the current lexical scope is inside a loop.

There was an ambiguity in the semantics for the \texttt{for} statement
in that it is not specified in what lexical environment the upper and
lower bounds are evaluated.  The following code illustrates this:
\begin{verbatim}
{
  int i;
  i = 3;
  for(i=i+1; i*2) {
    ...
  }
}
\end{verbatim}

We decided that the bounds \texttt{i+1} and \texttt{i*2} should be
evaluated before creating a new binding for \texttt{i}, so the bounds
in this case are \texttt{4} and \texttt{6}.  The following code
illustrates how we accomplish the semantic check with this assumption
on semantics.
\begin{verbatim}
checkStatement (ForSt itok start end statement)
    = do t1 <- checkExpr start
         tInt <==> t1
         t2 <- checkExpr end
         tInt <==> t2
         local deriveEnv $ do -- create environment (shadows variable)
           addEnvBinding (tokenString itok) tInt -- add index variable
           enterLoop $ checkStatement statement
\end{verbatim}
The \texttt{deriveEnv} function takes the current lexical environment
and makes a new sub-environment.

\section{IR for Code Generation}
\label{sec:ir}

After finishing all Semantic Checks with the Unification system, the compiler 
creates a new IR called the ``Hybrid AST'' designed for ease of use for code 
generation. The ``Hybrid AST'' defined in SymbolTable.hs is a hybrid of an 
abstract syntax tree and a symbol table. It is constructed very similarly to 
the AST defined in AST.hs with the addition that each node in the AST now 
contains a reference to the ``Symbol Environment''  the node has access to. We 
decided to design the IR in this way because Code Generation will require us to 
have information pertaining to both the AST \emph{and} the symbol table.  
Combining the two into a hybrid data structure should simplify the process of 
code generation greatly.

The Symbol Environments are types that contain information about all symbols 
available at a certain portion of the program. Each Symbol Environment is 
composed of a Haskell Map mapping names to symbol information and a pointer to 
a Parent Symbol Environment. It is important to note that since Symbol 
Environments are deeply connected with the AST, the Symbol Environment 
\emph{does not} contain a reference to any of its children Symbol Environments.  
If that information is needed, then the AST will have to be navigated to find 
the child Symbol Environment, which will then have a reference to its parent 
Symbol Environment. We chose to design the IR this way for greater simplicity 
and we believe this decision is correct because a node in the program would 
normally not have any access to symbols declared in a child environment, so 
providing this information in the Symbol Environments would serve no useful 
purpose.  

The Hybrid AST is created directly from the AST generated by the parser. Since 
the Hybrid AST is only created after the program has passed all semantic 
checks, it operates under the assumption that there are no semantic errors. The 
Haskell typeclass ``HybridAST'' defines a function called ``createHybridAST'' 
with type \begin{verbatim}
createHybridAST :: SymbolEnv -> a -> b
\end{verbatim} 

SymbolTable.hs then defines an instance of HybridAST for each type representing 
a node in the AST (from AST.hs) that transforms a node of that type into a 
corresponding hybrid node that contains the SymbolEnv information. The 
createHybridAST function also handles creating and populating the Symbol 
Environments.

For printing purposes the only nodes in the Hybrid AST that print their 
corresponding Symbol Environments are the nodes that derive a new symbol 
environment (such as method decls, blocks, and for statements). 

\section{Test Plan}
\label{sec:test}
The tests/semantics directory contains at least one illegal file for each 
semantic rule - these tests test exactly one semantic rule that fails. They 
have been immensely useful over the course of this project. We also modified 
test.sh to conceal the output of the Semantic Checker when the test succeeds, 
which makes things a lot cleaner, and prevents the tester from having to scan 
past the print outs of the Hybrid ASTs.


\end{document}
