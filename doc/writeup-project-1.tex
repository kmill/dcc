\documentclass[11pt]{article}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{fullpage}

\title{6.035 Project 1}
\author{Kyle Miller, Patrick Hulin, Alec Thomson, Steven Valdez}
\begin{document}
\maketitle

\section{Overview} 

For this project, we extended the decaf scanner/parser created in project 0 to check for semantic errors and to build a useful intermediate representation for code generation. The project is split up into two distinct phases that can occur in parallel: semantic checking and IR generation. 

When \texttt{--target inter} is specified on the command line, the compiler will perform all semantic checks on the input program. If there are no semantic errors and \texttt{--debug} is specified, the compiler will then generate a ``Hybrid AST'' (outlined in Section~\ref{sec:ir}) and print this IR to the terminal. 

\section{Division of Work} 

For this project, Kyle wrote all of the code corresponding to the actual semantic checker (Section~\ref{sec:checker}), available in SemanticCheck.hs, and Unify.hs. Alec wrote the code corresponding to the IR for Code Generation (Section~\ref{sec:ir}) available in SymbolTable.hs. Patrick created a large suite of test-cases (Section~\ref{sec:test}) that went beyond the cases provided in the skeleton. 

\section{Semantic Checker}
\label{sec:checker}

The semantic checker takes the AST generated by the parser and
determines whether the AST is semantically valid by evaluating the
tree in a context which keeps track of the types of all of the
variables defined in the current lexical scope, whether the current
scope is inside a looping construct, the current unification data, and
a list of all of uncovered the semantic errors.

For semi-intelligent error messages, we decided to use the unification
algorithm to drive the type-checking required by the semantics for
Decaf.  This gives the semantic checker the ability to infer the types
of undefined variables to provide the user with helpful error message
as well as to be able to simplify the problem of over-reporting an
error (for instance, if \texttt{x} is an undefined variable, then the
expression \texttt{x + x} will only report one error, that \texttt{x}
is undefined, since unification will infer that \texttt{x} must be an
integer for addition to make sense).

The unification algorithm take two structures, which in our case are
trees representing types, where free variables (called ``unification
variables'') can be used in place of substructures, and finds minimal
assignments to the variables which makes the two structures equal.
For instance, unifying \texttt{Array($x$)} with \texttt{Array(Int)}
gives the binding $x=\mathtt{Int}$.  A unification error occurs when
two structures are unable to be unified, such as \texttt{Int} with
\texttt{Bool} or \texttt{Array(Int)} with \texttt{Func($x$, [Int,
  Boolean])}.

The unification algorithm occurs in a unification monad of the
typeclass \texttt{BindingMonad} (defined in \texttt{Unify.hs}) which
keeps track of the bindings for unification variables and generates
new unification variables as needed.  When a \texttt{BindingMonad}
reaches a unification error, the entire computation short circuits
with an exception.

The semantic checker monad defined in \texttt{SemanticCheck.hs} holds
a copy of the \texttt{BindingMonad} state so that unification
variables can be remembered through the entire semantic check.  This
prevents the code \texttt{x = 1; x += 2;} when \texttt{x} is not
defined from issuing more errors than the error of \texttt{x} not
being defined.  The actual mechanism by which this is accomplished is
that, when checking \texttt{x = 1;}, the semantic checker evaluates
the types for \texttt{x} and \texttt{1}.  The integer literal
\texttt{1} is of type \texttt{Int}, and, since the location \texttt{x}
is not defined, the semantic checker adds it to the current lexical
scope with a new unification variable $x$ as its type.  Since
assignment requires that both sides be of the same type, we unify $x$
with \texttt{Int}, giving $x=\mathtt{Int}$.  Hence, when checking
\texttt{x += 2;}, we know that the location \texttt{x} in the
expression has \texttt{Int} as its type.

In particular, the unification lets us write code like the following,
which is almost what is found in \texttt{SemanticCheck.hs} except that
source position handling has been removed.  The operator \texttt{<==>}
is the unification operator, representing equality with the action of
inserting bindings from one structure into the other and vice versa.

\begin{verbatim}
checkStatement (AssignSt loc assop expr)
    = do dtype <- checkLocation loc
         etype <- checkExpr expr
         case assop of
           Assign -> do checkIsScalar etype
                        dtype <==> etype
           -- Otherwise, assop is IncAssign or DecAssign
           _ -> do etype <==> tInt
                   dtype <==> tInt
\end{verbatim}

With the input having the \texttt{x = 1; x += 2;} example, the above
code issues only the following error.
\begin{verbatim}
"<stdin>" (line 3, column 5)
    x = 1;
    ^
Unbound identifier "x".  Inferred type is "int".
\end{verbatim}

The unification operator, on a unification error, appends the error to
the list of discovered semantic errors inside the semantic check
monad.  Other semantic checks are handled in ways analogous to the way
\texttt{break} statements are handled:
\begin{verbatim}
checkStatement (BreakSt pos)
    = do env <- ask
         case isInsideLoop env of
           True -> return ()
           False -> addError $ SemBreakOutsideLoop pos
\end{verbatim}%$
Loops (such as the \texttt{for} statement included below) set whether
the current lexical scope is inside a loop.

There was an ambiguity in the semantics for the \texttt{for} statement
in that it is not specified in what lexical environment the upper and
lower bounds are evaluated.  The following code illustrates this:
\begin{verbatim}
{
  int i;
  i = 3;
  for(i=i+1; i*2) {
    ...
  }
}
\end{verbatim}

We decided that the bounds \texttt{i+1} and \texttt{i*2} should be
evaluated before creating a new binding for \texttt{i}, so the bounds
in this case are \texttt{4} and \texttt{6}.  The following code
illustrates how we accomplish the semantic check with this assumption
on semantics.
\begin{verbatim}
checkStatement (ForSt itok start end statement)
    = do t1 <- checkExpr start
         tInt <==> t1
         t2 <- checkExpr end
         tInt <==> t2
         local deriveEnv $ do -- create environment (shadows variable)
           addEnvBinding (tokenString itok) tInt -- add index variable
           enterLoop $ checkStatement statement
\end{verbatim}
The \texttt{deriveEnv} function takes the current lexical environment
and makes a new subenvironment.

\section{IR for Code Generation}
\label{sec:ir}

After finishing all Semantic Checks with the Unification system, the compiler creates a new IR called the ``Hybrid AST'' designed for ease of use for code generation. The Hybrid AST' defined in SymbolTable.hs is a hybrid of an abstract syntax tree and a symbol table. It is constructed very similarly to the AST defined in AST.hs with the addition that each node in the AST now contains a reference to the ``Symbol Environment''  the node has access to. We decided to design the IR in this way because Code generation will require us to have informatio pertaining to both the AST \emph{and} the symbol table. Combining the two into a hybrid data structure should simplify the process of code generation greatly.

The Symbol Environments are types that contain information about all symbols available at a certain portion of the program. Each Symbol Environment is composed of a Haskell Map mapping names to symbol information and a pointer to a Parent Symbol Environment. It is important to note that since Symbol Environments are deeply connected with the AST, a Symbol Environment \emph{does not} contain a reference to any of its child Symbol Environments. If that information is needed, then the AST will have to be navigated to find the child Symbol Environment, which will then have a reference to its parent Symbol Environment. We chose to design the IR this way for greater simplicity and we believe this decision is correct because a node in the program would normally not have any access to symbols declared in a child environment, so providing this information in the Symbol Environments would serve no useful purpose. 

The Hybrid AST is created directly from the AST generated by the parser. Since the Hybrid AST is only created after the program has passed all semantic checks, it operates under the assumption that there are no semantic errors. The Haskell typeclass ``HybridAST'' defines a function called ``createHybridAST'' with type 
\begin{verbatim}
createHybridAST :: SymbolEnv -> a -> b
\end{verbatim} 

SymbolTable.hs then defines an instance of HybridAST for each type representing a node in the AST (from AST.hs) that transforms a node of that type into a corresponding hybrid node that contains the SymbolEnv information. The createHybridAST function also handles creating and populating the Symbol Environments.

For printing purposes the only nodes in the Hybrid AST that print their corresponding Symbol Environments are the nodes that derive a new symbol environment (such as method decls, blocks, and for statements). 

\section{Test Plan}
\label{sec:test}
The tests/semantics directory contains at least one illegal file for each semantic rule - these tests test exactly one semantic rule that fails. They have been immensely useful over the course of this segment of the project. We also modified test.sh to not print the output of the compiler when the test succeeds, which makes things a lot cleaner.


\end{document}
