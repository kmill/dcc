\documentclass[11pt]{article}

\usepackage{amsmath, amsfonts,amssymb,amsthm}
\usepackage{fullpage}

\title{6.035 Project 4 Writeup}
\author{Kyle Miller, Alec Thomson, Patrick Hulin, Steven Valdez}
\begin{document}
\maketitle

\section {Instructions for Building and Running the Project}

\section {Overview}



\section {Division of Work}

The work was divided as follows. Kyle Miller designed and implemented
the register allocator along with a slew of peephole optimizations
that occurred at the code generation level. Kyle also wrote part of
the code generator portion of the loop parallelizer and wrote web
analysis for the Mid IR that was essential for loop analysis. Alec Thomson wrote most of
the loop analysis routines, including all of the loop parallelization
analysis, the dominator analysis, the loop nesting analysis, and
several loop heuristics that were used by the register allocator and
code generator. Alec
also wrote the expression unflattener to aid with instruction
selection. Patrick Hulin helped write a portion of the loop
parallelizing code generator, wrote some loop invariant code analysis
that ultimately didn't make it in to the final product, and helped
manage the considerable test-suite. Steven Valdez wrote an expression
optimization involving elimination of conditional statements and also
helped manage the test-suite. 

\section {Algebraic Simplification} 


\section {Expression Unflattener}

The purpose of the expression unflattener is to return the mid-ir to
``Tree-Form'' after CSE is performed while maintaining the benefits
gained from CSE so that optimized Instruction Selection can be easily
performed by the code generator. The design, implementation, and test
plan of the unflattener are described below.

\subsection{Design of Expression Unflattener}

Our design first makes use of the liveness information
provided by dead-code elimination to determine which variables are
live at any given block in the mid-ir control flow graph. Once this
information is obtained, unflattening can be performed at the block
level.\\


\noindent Each block is then re-written according to the following algorithm: 

\begin{verbatim}
UnflattenBlock(block):

1. Determine the number of uses of each variable in this block 
2. Determine the reaching definitions of each variable defined in this
block
3. For each variable of each expression in this block: 
   1. If the variable is not live at any of this blocks successors 
      AND the variable is only used once in this entire block 
      (i.e. this is the only use)
      AND the variable is mapped to a reaching definition from this block 
   4. THEN replace the use of this variable with the expression from
its reaching definition
\end{verbatim}

\noindent The UnflattenBlock function is run on the same block until that block
reaches a fixed point. The general purpose of this algorithm is to
discover variables that are ``temporary'' in a given block and to replace
their uses with the expressions they were assigned to represent during
the flattening phase. Since the algorithm doesn't consider a variable
``temporary'' if it is used more than once (or if it is live in a
successor of this block), the benefits of CSE should be preserved
while the mid-ir is returned to tree-form. 

\subsection{Implementation of Expression Unflattener}

The expression unflattener is implemented in the Dataflow.hs source
file. The algorithm is roughly the same as the one described above
with some augmentations to allow for easy fixed point detection.

The first thing the implementation does is use the Hoopl liveness
analysis implemented as part of the previous project to obtain a
factbase of the live variables at the start of every block. Next it
maps the ``UnflattenBlock'' function across every block in the graph
to obtain a new graph with every block flattened to a fixed point. The
``UnflattenBlock'' function will call itself recursively if it detects
that it is returning a changed graph as a result of its
modifications. When ``UnflattenBlock'' no longer has an effect, the
algorithm terminates.

After unflattening every block in the graph, the algorithm then
concludes by performing dead code elimination again to eliminate
assignments to temporaries that are no longer being used.

\subsection{Experimental Results of Expression Unflattener}

The unflattener passes our entire test suite and appears to work
correctly. The figures below show the unflattener operating on a
simple program. The second figure shows how the unflattener maintains
the benefits obtained from CSE. 

% TODO: Put the before and after graphs right here for unflattentest1 and unflattentest2

\section {Conditional Elimination} 


\section {Register Allocation}

\section{Loop Parallelizer}

The loop parallelizer splits the control flow into multiple threads
for loops with expensive bodies with no inter-run dependencies. The
analysis runs at the mid IR level 

The design of the loop parallelizer is split into two major parts,
loop analysis and code generation. The loop analysis portion is
concerned with discovering loops that can be parallelized while making
no transformations to the IR. The loop analysis portion is also
responsible for running a heuristic that determines whether loops
should be parallelized considering the overhead of thread
creation. The code generation portion uses the analysis information to 
generate appropriate code to split the loops among many different
threads.

\subsection { Loop Analysis } 

Loop analysis is a multi-stage process that operates on the mid IR
after most of the Mid IR dataflow transformations have completed. We
chose to operate on the Mid IR because it allowed us to parallelize
for-loops and while-loops equally while reaping the full benefits of
constant and copy propagation. The major stages of loop analysis,
described in detail below, are Dominator Analysis, Loop
Identification, Induction Variable Identification, Loop Invariance
Analysis, and Cross Dependency Analysis. Ultimately, the analyzer uses
the integer programming method with the help of the glpk-hs library to
solve the cross dependency constraints. 

\subsubsection {Dominator Analysis} 

A useful first step in performing loop analysis was to discover the
dominator map of the midir. To do so, we used a simple forwards
dataflow analysis using Hoopl. The fact type was a set of dominators
while the join function was set intersection with bottom being
represented by the abstract ``Bot'' type. 

The transfer function was very simple and only updated the set of
dominators at entry and exit points of the blocks. Ultimately, Hoopl
took care of most of the analysis and there was no need to rewrite any
portion of the graph. 

The dominator map produced by this analysis was then a map from
block labels to the sets of dominators of those blocks. The dominator
map proved essential to the discovery of loops, loop induction
variables, and loop invariant expressions and variables. 

\subsubsection {Loop Identification}

Once dominator analysis was complete, loops could be identified by
what Muchnick refers to as a ``Back-Edge''. A back-edge is any edge in
the control flow graph that points from a block (referred to as the
``loop-back'' in our code) to one of its dominators (referred to as
the ``loop-header''). Once a back-edge has been identified, the body
of the ``Natural Loop'' can be found by looking for all of the blocks
that are capable of reaching the loop-back \emph{without} travelling
through the loop-header.  

To find all of the blocks in the loop body, another custom dataflow
analysis was performed called ``loop-reaching'' analysis that
ultimately identified all the blocks in the control-flow graph that
could reach the loop-back without travelling through the
loop-header. This was a backwards dataflow analysis with a boolean
fact type that returned the set of blocks belonging to the natural
loop body. 

After the body of the natural loop was discovered, additional blocks
needed to be added to the loop body that were not caught by the
reaching analysis. These blocks were those that ended in return or
fail statements and thus wouldn't be identified as part of the natural
loop but should be considered to be part of the loop body. In
particular fail statements were an essential part of the loop body as
they were placed there by run-time array bounds checks. 

\subsubsection {Induction Variable Identification} 

After loop bodies were identified, the next was identification of the
base induction variables. Since loop analysis is done at the Mid-IR,
identification of base induction variables is slightly more
complicated than just looking at the variable used in the decleration
of a for loop. Fortunately, since the process identifies any base
induction variable without looking at high level code, while loops and
for loops can be analyzed identically. For example, at the mid ir
level, the code 

\begin{verbatim} 

for(i=0; N) { 
// Do Stuff
}

\end{verbatim}

\noindent is effectively identical to 

\begin{verbatim} 

i=0; 
while(i < N) { 
// Do Stuff 
i+=1;
}

\end{verbatim} 

\noindent To aid in identification of induction variables, a set of
mid level ``webs'' were constructed for the mid ir graph. The mid
level webs are a set of Def-Use chains that are essentially the webs
defined in the register allocation lecture. Once a set of webs has
been produced for the entire mid level graph, 

\subsubsection {Loop Invariance Analysis} 


\subsubsection {Dependency Analysis}

\subsection{Code Generation}

% stuff about loop analysis

The parallelizer makes use of a new instruction in our mid-ir,
"Parallel". This instruction is inserted before the loop, and the
loop's induction variable update instructions are modified in order to
only execute some of the loop's executions in each run.

% stuff about code generation

\subsection{Results}

Below are some examples of some code that gets generated by the
parallelizer. With a loop cost threshold of about 1000000, we found
that parallelization could provide up to a 75\% speedup on
specifically designed tests (such as matrix multiply). On test cases
that were almost exclusively parallel loops, the parallelizer could
produce speedup results close to the number of cores on the target
machine. 

% add some graphs

\section{Loop Invariant Code Motion}

Loop Invariant Code Motion (LICM) moves loop-invariant instructions
out of loops so they execute less frequently. The optimization is
important because some compiler-generated instructions are
loop-invariant and get repeated over and over, which is clearly a
waste of resources. The implementation consists of a dataflow analysis
and a non-local rewrite function: the rewrite function uses the State
monad to ensure that instructions only get moved once.

\section{Conclusion}


\end{document}
